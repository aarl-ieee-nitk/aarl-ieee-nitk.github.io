# Adversarial Attacks in Reinforcement Learning

This repository serves code, blogs and other related work pertaining to the 'Adversarial Attacks in Reinforcement Learning'

Following are the posts on the blog:

* [Survey on Adversarial Attacks and Defenses in Reinforcement Learning](https://aarl-ieee-nitk.github.io/reinforcement-learning,/adversarial/attacks,/defense/mechanisms/2020/04/09/Survey-on-Adversarial-attacks-and-defenses.html)

* [Proximal Policy Optimization](https://aarl-ieee-nitk.github.io/reinforcement-learning,/policy-gradient-methods,/sampled-learning,/optimization/theory/2020/03/25/Proximal-Policy-Optimization.html)

* [Trust Region Policy Optimization](https://aarl-ieee-nitk.github.io/reinforcement-learning,/policy-gradient-methods,/sampled-learning,/optimization/theory/2020/03/12/Trust-Region-Policy-Optimization.html)

* [Understanding Policy Gradients](https://aarl-ieee-nitk.github.io/reinforcement-learning,/policy-gradients/2019/12/26/policy-gradients.html)

* [Temporal-Difference Learning](https://aarl-ieee-nitk.github.io/reinforcement-learning,/value-based-learning,/bootstrapped-learning,/sampled-learning/2019/12/19/Temporal-Difference-Learning.html)

For the code, checkout [this](https://github.com/IEEE-NITK/Adversarial-RL) repository.

## Team
* Madhuparna Bhowmik
* Akash Nair
* Saurabh Agarwala
* Videh Raj Nema
* Kinshuk Kashyap
* Manav Singhal

Mentor: Moksh Jain
